{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data that has been wrangled is data from https://mapzen.com/data/metro-extracts/metro/jakarta_indonesia/\n",
    "\n",
    "I originate from Indonesia so I thought it would be nice if I can explore the data that I should be familiar with. Thus, I can find the most common errors in data particularly in my area.\n",
    "\n",
    "# Problems Encountered in the Map\n",
    "\n",
    "There are several issues found in the data, mostly came from the `tag` tag.\n",
    "\n",
    "1. Inconsistent address format, some only including address, residencial cluster,\n",
    "```\n",
    "\\xc3\\xa2\\xc2\\x80\\xc2\\x8eJl. Ir. H. Djuanda No. 95'\n",
    "JI.Margonda Raya No. 428, Beji, Depok , Indonesia'\n",
    "'M.I. RIDWAN RAIS NO. 37, Beji Timur. Depok'\n",
    "'Sentra Niaga Puri Indah'\n",
    "'Pamulang Permai blok D III no. 1-2',\n",
    "'22'\n",
    "```\n",
    "\n",
    "2. Wrong formatted postal codes\n",
    "```\n",
    "b'16127.'\n",
    "b'14450.'\n",
    "b'11550.'\n",
    "b'\\xc3\\xa2\\xc2\\x80\\xc2\\x8e15414'\n",
    "b'Lippo Karawaci 1600 Tangerang 15811'\n",
    "b'151416'\n",
    "```\n",
    "\n",
    "3. Inconsistent language used on city\n",
    "```\n",
    "'Jakarta Selatan',\n",
    "'South Jakarta',\n",
    "```\n",
    "\n",
    "4. Incosistent Phone number\n",
    "```\n",
    "'+62 21 799 0888',\n",
    "'+62 21 5263137',\n",
    "'14045',\n",
    "'622178834966',\n",
    "'+62 8983 2943',\n",
    "'(0251) 831 6348',\n",
    "```\n",
    "\n",
    "Thus, before the data exported into the database, these errors should be cleaned. Below are the logic behind the data cleaning respect to each error.\n",
    "\n",
    "1. To clean the in consistent address format, in this case the street (Jalan) naming, following algorithm conducted:\n",
    "    - Replace all abbreviated \"Jalan\" such as jl, jln, Jln., and so on.\n",
    "    - Delete all double spaces such as \"Jalan  A\"\n",
    "    - Remove all non ASCII character in the street name such as \"\\xe2\\x80\\x8eJalan Ir. H. Djuanda No. 95\" (mostly we do not use any latin/utf characters. However, we need more research on this)\n",
    "    - Remove all non address and its number from the text, such as city name and country\n",
    "\n",
    "    Thus, below is the code function:\n",
    "\n",
    "    ```\n",
    "    ADDRESS_ABBRV = re.compile(r'(j|J)(l|ln|I|L|LN)(\\s|\\.)|jalan')\n",
    "    \n",
    "    def fix_address(data):\n",
    "        data = ADDRESS_ABBRV.sub('Jalan ', data)\n",
    "        data = data.replace(\"  \", \" \") #delete double spaces\n",
    "        data = data.encode('ascii', 'ignore').decode() #remove unicode characters\n",
    "        if 'Jalan' not in data:\n",
    "            data = \"Jalan \"+ data\n",
    "        for value in re.split(',\\s|,', data):\n",
    "            if \"Jalan\" in value:\n",
    "                data = value\n",
    "        return data\n",
    "    ```\n",
    "    \n",
    "2. To clean the postal code is quite simple, it only need a regex as follows:\n",
    "    ```\n",
    "    POSTAL_CODE = re.compile(r'[0-9]{5}')\n",
    "    \n",
    "    def fix_postal(data):\n",
    "    if len(POSTAL_CODE.findall(data)) > 0:\n",
    "        return POSTAL_CODE.findall(data)[0]\n",
    "    else:\n",
    "        return '00000'\n",
    "    ```\n",
    "\n",
    "3. It interesting in Indonesia sometimes we confused when to use english or bahasa. Thus, the inconsistent language may occurs in city name such as South (Selatan), to \"simple\" fix the issue, I have provided a simple dictionary as follows to tranlate all to bahasa: \n",
    "    ```\n",
    "    CITY_TRANSLATION = {\n",
    "        \"south jakarta\": \"Jakarta Selatan\",\n",
    "        \"north jakarta\": \"Jakarta Utara\",\n",
    "        \"west jakarta\": \"Jakarta Barat\",\n",
    "        \"east jakarta\": \"Jakarta Timur\",\n",
    "        \"central jakarta\": \"Jakarta Pusat\"\n",
    "    }\n",
    "    ```\n",
    "    However, it is just a simple fix, further development such as per-word/context translation may help this better.\n",
    "\n",
    "4. Generally every people have their own format for their phone number, as as \"simple\" fix, I remove all the special character in phone number to make it more consistent.\n",
    "  \n",
    "\n",
    "\n",
    "# Overview of the Data\n",
    "As a general overview, there are 16071868 lines that were processed resulting following files.\n",
    " ```\n",
    "    jakarta_indonesia.osm: 3.04 GB\n",
    "    nodes.csv: 1.45 GB\n",
    "    nodes_tags.csv: 17.9 MB\n",
    "    ways.csv: 253 MB\n",
    "    ways_nodes.csv: 507.4 MB \n",
    "    ways_tags.csv: 703.5 MB\n",
    "    pythonsqlite.db: 2.13 GB\n",
    "    ```\n",
    "\n",
    "### Number of Unique Users\n",
    "```\n",
    "sqlite> SELECT COUNT(DISTINCT(com.uid)) FROM (SELECT uid FROM node UNION ALL SELECT uid FROM way) com;\n",
    "\n",
    "2467\n",
    "```\n",
    "\n",
    "\n",
    "### Number of Nodes and Ways\n",
    "```\n",
    "sqlite> SELECT COUNT(*) FROM node;\n",
    "\n",
    "12994948\n",
    "\n",
    "sqlite> SELECT COUNT(*) FROM way;\n",
    "\n",
    "3076920\n",
    "```\n",
    "\n",
    "### Top Contributed Users\n",
    "```\n",
    "sqlite> SELECT uid, user, COUNT(uid) AS cnt FROM node WHERE uid IN (SELECT uid FROM node UNION ALL SELECT uid FROM way) GROUP BY uid ORDER BY cnt DESC LIMIT 10;\n",
    "\n",
    "4159996|Akrimullah|970757\n",
    "5539627|Yeni Primasari|471231\n",
    "2901733|adiatmad|457934\n",
    "4706330|endang_p|397020\n",
    "5520501|Dion Qairawan|389632\n",
    "5520505|Hanif Arafah Mustofa|362426\n",
    "1840603|martinmbaihaqi|353253\n",
    "538459|Alex Rollin|349773\n",
    "5454005|Riyadi Wibowo|326414\n",
    "136807|Farras|323898\n",
    "```\n",
    "\n",
    "### Number of Top 10 City\n",
    "```\n",
    "sqlite> SELECT value, COUNT(value) FROM node_tags WHERE key = 'city' GROUP BY value ORDER BY COUNT(value) DESC LIMIT 10;\n",
    "\n",
    "DKI Jakarta|15208\n",
    "Jakarta Selatan|964\n",
    "Jakarta Pusat|528\n",
    "Jakarta Barat|504\n",
    "Bekasi|412\n",
    "Jakarta Utara|280\n",
    "Jakarta Timur|272\n",
    "Banten|220\n",
    "Depok|188\n",
    "Tangerang|108\n",
    "```\n",
    "\n",
    "It is interesting that DKI Jakarta can be considered either as Jakarta Selatan, Jakarta Pusat, Jakarta Barat, Jakarta Utara, and Jakarta Timur because it is a special region, DKI Jakarta sometimes misinterpreted as a city, in fact it is a province.\n",
    "\n",
    "\n",
    "# Other ideas about the dataset\n",
    "\n",
    "### Issue and Suggestion\n",
    "The main issue faced on the dataset is the size of the data, it took very long time and too much information that can hinder exploration efficiency. To overcome the issue, I explore the file with limited number of lines. For example, only 200000 out of 16071868 lines were explored to find ill presented data. However, this method will leave other potential problems in the data that never be explored (can be seen in Number of Top 10 City, if I not limit the result, it will show more error such as West Java, it should be a province not a city). Thus, it is best to use more specific/smaller data area to be explored as it may reduce load of computing tasks and time. \n",
    "\n",
    "Another suggestion, to reduce inconsistent data values, OSM can implement value suggestion based on previous data or implement token normalisasion based on dictionary of previous correct data. However, this approach may reduce flexibility of new terms, such as address or buildings. Thus it should be very careful where to implement this suggestion, a good implementation can be applied to City, Province, or Postal Code value.\n",
    "\n",
    "### Other Experiment on the Data\n",
    "#### Top 10 Key Used and the User\n",
    "```\n",
    "sqlite> SELECT user, key, COUNT(key) cnt FROM node, node_tags WHERE node.id = node_tags.id GROUP BY user, key ORDER BY cnt DESC LIMIT 10;\n",
    "\n",
    "   User     |    Key     | Count\n",
    "   \n",
    "Firman Hadi   created_by   45436\n",
    "Alex Rollin   natural      20780\n",
    "adiatmad      source       17836\n",
    "Alex Rollin   type         6900\n",
    "ceyockey      source       5004\n",
    "gafuri        natural      3700\n",
    "ceyockey      natural      3324\n",
    "jeffhaack     country      3304\n",
    "jeffhaack     name         3304\n",
    "jeffhaack     place        3304\n",
    "```\n",
    "It is interesting that the highest key is is not inputted by the highest contributor. Further experiment to find what keys that inputted by the top contributor.\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "There are many issues found on the OSM data. It might be because its nature as open source platform that promotes flexibility. However, the most common drawback is inconsistent values, typo, etc. Furthermore, the data that explored in this project is very big (2.13 GB in total in the db) which lead to unadequate time for exploration. Thus, smaller dataset is more favourable. \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
